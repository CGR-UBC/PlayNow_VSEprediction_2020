{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table 2 and Table 3: \n",
    "# Random Forest and Logistic Regression Classification Results \n",
    "\n",
    "This notebook contains code for the Random Forest Classification and Logistic Regression Classification Results in Table 2 and 3, that is, AUROC, sensitivity and specificity. To produce these results, parameters need to be adjusted in the following sections (clearly indicated below):  \n",
    "\n",
    "- in **data** section: inclusion threshold\n",
    "    - 200 bets or 10 sessions\n",
    "- in **pipeline** section: modeling parameters\n",
    "    - full or reduced variable set\n",
    "    - Random Forest Classification or Logistic Regression \n",
    "    - unbalanced (full) or balanced dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import random\n",
    "import datetime \n",
    "import pickle\n",
    "import os.path\n",
    "import warnings\n",
    "\n",
    "linestyles = ['solid', 'dotted', 'dashed','dashdot']  \n",
    "colors = ['b','r','k','#FFFF00','g','#808080','#56B4E9','#FF7F00']\n",
    "markers = ['.','+','s']\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%run _helper.ipynb\n",
    "%run _feature_selection_class.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = ''\n",
    "output_path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################### SELECT INCLUSION THRESHOLD ###################\n",
    "\n",
    "inclusion_var, inclusion_threshold = 'total_bets',200  # >200 bet threshold\n",
    "#inclusion_var, inclusion_threshold = 'total_number_of_sessions',10 # sensitivity analysis: >10 session threshold\n",
    "\n",
    "#################################################################\n",
    "\n",
    "\n",
    "# load\n",
    "data = pd.read_csv(input_path)\n",
    "header = list(data)[1:-1]\n",
    "\n",
    "# subset data\n",
    "data = data[data[inclusion_var] > inclusion_threshold]\n",
    "\n",
    "# summary\n",
    "print('total: ',len(data))\n",
    "print('columns: ',len(header))\n",
    "print('non-vse: ',len(data[data.exclusion==0]))\n",
    "print('vse: ',len(data[data.exclusion==1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframes to store results\n",
    "df_results = get_df_results('df_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyperparms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "BOOTSTRAP = [True, False]\n",
    "CRITERION = ['entropy', 'gini']\n",
    "MAX_FEATURES = [0.1, None, 'log2', 'sqrt']\n",
    "N_ESTIMATORS = [20, 60, 100, 500, 1000]\n",
    "MAX_DEPTH = [10, 20, 50, None]\n",
    "MIN_SAMPLES_SPLIT = [2,30,100]\n",
    "N_JOBS = [-1]\n",
    "RANDOM_STATE = [123]\n",
    "\n",
    "# Logit\n",
    "C_VALUE = [0.1, 0.5, 1, 1.5, 2]\n",
    "MAX_ITER = [300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# NESTED CROSS VALIDATION \n",
    "n_splits = 10\n",
    "\n",
    "\n",
    "################### SELECT MODELING PARAMETERS ###################\n",
    "\n",
    "# 1. FULL VS SELECTED VARIABLES \n",
    "#featureselector = 'passthrough' # use all 20 variables\n",
    "featureselector = VariableSelector() # use 6 selected variables\n",
    "\n",
    "# 2. ESTIMATOR\n",
    "estimator = RandomForestClassifier()\n",
    "#estimator = LogisticRegression()\n",
    "\n",
    "# 3. DATASET MODE\n",
    "mode = 'full' # full dataset\n",
    "#mode= 'balanced' # balanced dataset\n",
    "\n",
    "##################################################################\n",
    "\n",
    "\n",
    "# initialize  \n",
    "X,y = get_dataset_full_or_balanced(mode=mode, \n",
    "                                   data=data, \n",
    "                                   header=header)\n",
    "param_grid = get_param_grid(estimator)\n",
    "pipe, analysis_type, variables, model = get_pipeline(featureselector=featureselector, \n",
    "                                                     estimator=estimator, \n",
    "                                                     inclusion_var=inclusion_var)\n",
    "\n",
    "\n",
    "# confirm\n",
    "print('analysis type:',analysis_type )\n",
    "print('model:', model)\n",
    "print('mode:', mode, 'size:', len(X))\n",
    "print('variables:', variables)\n",
    "print('n_splits:', n_splits)\n",
    "print('pipeline:',pipe)\n",
    "print('param_grid:', param_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nested cross-validation (AUROC) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "# define cross-validation technique\n",
    "inner_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123)\n",
    "outer_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123)\n",
    "\n",
    "# set up grid search\n",
    "# note: refit=True refits best estimator with best hyperparms on entire outer training fold.\n",
    "grid_search = GridSearchCV(pipe, cv=inner_cv, n_jobs=-1, param_grid=param_grid, iid=False, scoring='roc_auc',\n",
    "                          refit=True)\n",
    "\n",
    "# nested cross-validation\n",
    "nested_cv = cross_validate(estimator=grid_search, \n",
    "                           X=X, y=y, \n",
    "                           scoring='roc_auc', \n",
    "                           cv=outer_cv,\n",
    "                           error_score=np.nan, \n",
    "                           #n_jobs=-1, \n",
    "                           return_estimator=True,\n",
    "                           return_train_score=True)\n",
    "runtime=time.time()-start_time\n",
    "print('Runtime: ', runtime, 'seconds')\n",
    "\n",
    "# selecting hyperparms\n",
    "clf_final = GridSearchCV(estimator, \n",
    "                    cv=inner_cv, n_jobs=-1, param_grid=param_grid, iid=False, scoring='roc_auc',\n",
    "                          refit=True).fit(X,y)\n",
    "runtime=time.time()-start_time\n",
    "print('Runtime: ', runtime, 'seconds')\n",
    "\n",
    "\n",
    "# AUROC values for train and test\n",
    "mean_train = nested_cv['train_score'].mean()\n",
    "std_train = np.std(nested_cv['train_score'])\n",
    "mean_test = nested_cv['test_score'].mean()\n",
    "std_test = np.std(nested_cv['test_score'])\n",
    "\n",
    "print('################## Performance Metrics for', model, '##################')\n",
    "\n",
    "print('analysis type:',analysis_type )\n",
    "print('model:', model)\n",
    "print('dataset:', dataset, 'size:', len(X))\n",
    "print('variables:', variables)\n",
    "print('Average ROC AUC train:',np.round(mean_train, 2), ' std:', np.round(std_train, 2))\n",
    "print('Average ROC AUC test:',np.round(mean_test, 2), ' std:', np.round(std_test, 2))\n",
    "print('Best hyperparms:', clf_final.best_params_)\n",
    "\n",
    "print('##################################################################################')\n",
    "\n",
    "if variables != 'full_vars':\n",
    "    selected_columns = clf_final.best_estimator_['featureselect'].results['selected columns']\n",
    "else: \n",
    "    selected_columns = 'NA'\n",
    "\n",
    "now = (datetime.datetime.now()-datetime.timedelta(hours=7)).strftime(\"%Y-%m-%d_%H:%M\")\n",
    "\n",
    "\n",
    "# store output in dataframe\n",
    "ml = '_'.join((model,analysis_type,mode,variables))\n",
    "df_auroc.loc[df_auroc.index == ml,'auc_mean_train'] = np.round(mean_train, 2)\n",
    "df_auroc.loc[df_auroc.index == ml,'auc_std_train'] = np.round(std_train, 2)\n",
    "df_auroc.loc[df_auroc.index == ml,'auc_mean_test'] = np.round(mean_test, 2)\n",
    "df_auroc.loc[df_auroc.index == ml,'auc_std_test'] = np.round(std_test, 2)\n",
    "df_auroc.loc[df_auroc.index == ml,'best_parms_final'] = clf_final.best_params_\n",
    "df_auroc.loc[df_auroc.index == ml,'selected_columns'] = selected_columns\n",
    "df_auroc.loc[df_auroc.index == ml,'timestamp']= now\n",
    "\n",
    "\n",
    "# save objects\n",
    "save_obj(path=output_path + '_'.join([ml, 'nested']), obj=nested_cv)\n",
    "save_obj(path=output_path + '_'.join([ml, 'final']), obj=clf_final)\n",
    "save_obj(output_path + 'df_results', obj=df_results)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# classifications (recall, specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "data = pd.read_csv(input_path)\n",
    "header = list(data)[1:-1]\n",
    "\n",
    "# get list of models in df_results\n",
    "#models = [i for i in df_results[df_results.iloc[:,0].notnull()].index]\n",
    "models = [i for i in df_results.index]\n",
    "\n",
    "# get splits\n",
    "n_splits=10\n",
    "inner_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123)\n",
    "outer_cv = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123)\n",
    "\n",
    "# run simple 10-fold loop \n",
    "for model in models:\n",
    "    \n",
    "       # prep data\n",
    "    if 'main' in model:\n",
    "        d = data[data['total_bets']>200].copy()\n",
    "    else:\n",
    "        d = data[data['total_number_of_sessions']>10].copy()\n",
    "    \n",
    "    # get sample\n",
    "    if 'balanced' in model:\n",
    "        X,y = get_dataset_full_or_balanced(mode='balanced', data=d, header=header)\n",
    "    else:\n",
    "        X,y = get_dataset_full_or_balanced(mode='full', data=d, header=header)\n",
    "    \n",
    "    # load model\n",
    "    final = load_obj('../obj/' + model+'_final')\n",
    "    cutoff_points = []\n",
    "    predictions = []\n",
    "    y_true = []\n",
    "    for outer_fold, (train_index, test_index) in enumerate(outer_cv.split(X,y)):\n",
    "\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_test, y_test = X.iloc[test_index], y.iloc[test_index]    \n",
    "\n",
    "        clf = final.best_estimator_.fit(X_train, y_train)\n",
    "        y_pred = clf.predict_proba(X_test)[:,1]\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(y_test, y_pred)\n",
    "        cut_opt = get_optimal_cutoff_point(fpr, tpr, thresholds)\n",
    "\n",
    "        cutoff_points.extend([cut_opt])\n",
    "        predictions.extend(y_pred)\n",
    "        y_true.extend(y_test)\n",
    "    \n",
    "    cutoff_mean = np.mean(cutoff_points)\n",
    "    y_class = get_classification(predictions, cutoff=cutoff_mean)\n",
    "    conf_matrix = metrics.confusion_matrix(y_true, y_class)\n",
    "    recall = metrics.recall_score(y_true, y_class)\n",
    "    specificity = get_specificity(conf_matrix)\n",
    "    \n",
    "    df_results.loc[model,'mean_cutoff_opt'] = cutoff_mean\n",
    "    df_results.loc[model,'conf_matrix'] = conf_matrix\n",
    "    df_results.loc[model,'specificity'] = specificity\n",
    "    df_results.loc[model,'recall'] = recall\n",
    "\n",
    "    \n",
    "    \n",
    "# save objects\n",
    "save_obj(df_results, 'df_results')\n",
    "\n",
    "print('done')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
