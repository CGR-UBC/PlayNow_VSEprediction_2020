{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# helper\n",
    "\n",
    "This notebook contains helper-functions used throughout this repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load objects\n",
    "\n",
    "def save_obj(obj, path):\n",
    "    '''Save object to path.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    obj : any python object (model, dictionary, dataframe) to store\n",
    "    path : str\n",
    "    \n",
    "\n",
    "    '''\n",
    "    \n",
    "    with open(path + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(path):\n",
    "    '''Load object from path.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    with open(path + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tables 2 and 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataframe to store modeling results\n",
    "def get_df_results(path):\n",
    "    '''Load or create dataframe to store modeling results.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        return load_obj(path)\n",
    "    \n",
    "    else:\n",
    "        # define dataframe to store AUROC results\n",
    "        models_list = [\n",
    "              'random_forest_main_full_full_vars',\n",
    "              'random_forest_main_full_selected_vars',\n",
    "              'random_forest_main_balanced_full_vars',\n",
    "              'random_forest_main_balanced_selected_vars',\n",
    "              'random_forest_sens_full_full_vars',\n",
    "              'random_forest_sens_full_selected_vars',\n",
    "              'random_forest_sens_balanced_full_vars',\n",
    "              'random_forest_sens_balanced_selected_vars',\n",
    "              'logit_main_full_full_vars',\n",
    "              'logit_main_full_selected_vars',\n",
    "              'logit_main_balanced_full_vars',\n",
    "              'logit_main_balanced_selected_vars',\n",
    "              'logit_sens_full_full_vars',\n",
    "              'logit_sens_full_selected_vars',\n",
    "              'logit_sens_balanced_full_vars',\n",
    "              'logit_sens_balanced_selected_vars']\n",
    "        \n",
    "        df_results = pd.DataFrame(index = models_list,\n",
    "                                columns = ['auroc_mean_train', \n",
    "                                           'auroc_std_train', \n",
    "                                           'auroc_mean_test', \n",
    "                                           'auroc_std_test',\n",
    "                                           'best_parms_final',\n",
    "                                           'selected_columns',\n",
    "                                           'timestamp',                                                                                     'mean_cutoff_opt', \n",
    "                                           'conf_matrix', \n",
    "                                           'recall', \n",
    "                                           'specificity']\n",
    "                         )\n",
    "        \n",
    "        return df_results\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dataset (balanced or unbalanced)\n",
    "def get_dataset_full_or_balanced(mode, data, header, target='exclusion'):\n",
    "    '''Get balanced or unbalanced dataset.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    mode : str\n",
    "           'full' for unbalanced dataset, 'balanced' for balanced dataset\n",
    "    data : str \n",
    "           Dataset\n",
    "    header : array of strings\n",
    "             Array of variable names\n",
    "    target : str\n",
    "             Target variable\n",
    "             \n",
    "    '''\n",
    "    \n",
    "    # assign regressor matrix (X) and array with independent variable (y)\n",
    "    X = data[header]\n",
    "    y = data[target]\n",
    "\n",
    "    if mode=='balanced':\n",
    "        idx = y.index[y==1]\n",
    "        idx = idx.union(random.choices(population=y.index[y==0], k=len(idx)))\n",
    "        X=X.loc[idx]\n",
    "        y=y.loc[idx]\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get hyperparameter grid\n",
    "def get_param_grid(estimator): \n",
    "    '''Assemble hyperaparameter grid for hyperparameter search.\n",
    "    \n",
    "    Get hyperparameter grid for Random Forest Classifier and Logistic Regression \n",
    "    to use in sklearn.model_selection.GridSearchCV.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : sklearn.ensemble.RandomForestClassifier or sklearn.linear_model.LogisticRegression class\n",
    "\n",
    "    '''\n",
    "\n",
    "    # get parameter grid for Logistic Regression\n",
    "    if isinstance(estimator,LogisticRegression):\n",
    "        paramgrid = [\n",
    "            {\n",
    "                'classify__C': C_VALUE,\n",
    "                'classify__max_iter': MAX_ITER\n",
    "            }\n",
    "        ]\n",
    "\n",
    "\n",
    "    # get parameter grid for Random Forest Classifier\n",
    "    elif isinstance(estimator,RandomForestClassifier):\n",
    "        paramgrid = [\n",
    "            {\n",
    "                'classify__bootstrap': BOOTSTRAP,\n",
    "                'classify__criterion': CRITERION,\n",
    "                'classify__max_features': MAX_FEATURES,\n",
    "                'classify__n_estimators': N_ESTIMATORS,\n",
    "                'classify__max_depth': MAX_DEPTH,\n",
    "                'classify__min_samples_split': MIN_SAMPLES_SPLIT,\n",
    "                'classify__n_jobs': N_JOBS,\n",
    "                'classify__random_state': RANDOM_STATE\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    else:\n",
    "        print('WARNING: Estimator not found.')\n",
    "        sys.exit()\n",
    "\n",
    "        \n",
    "    \n",
    "    return paramgrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "def get_pipeline(\n",
    "             featureselector, \n",
    "             estimator, \n",
    "             inclusion_var):\n",
    "    ''' Assemble pipeline to use in sklearn.pipeline.\n",
    "    \n",
    "    Initialize the sklearn.pipeline.Pipeline class, consisting of a \n",
    "    feature selection stage and the classification (estimator) stage. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    featureselector : str ('passthrough') or VariableSelector() class\n",
    "                      If 'passthrough', no feature selection is performed.\n",
    "    estimator : sklearn.ensemble.RandomForestClassifier or sklearn.linear_model.LogisticRegression class\n",
    "    inclusion_var : str\n",
    "                    Determines whether 200 bet threshold or 10 session threshold is used \n",
    "    '''\n",
    "    \n",
    "    # initialize pipeline\n",
    "    pipe = Pipeline([\n",
    "    ('featureselect', featureselector),\n",
    "    ('classify', estimator)])\n",
    "        \n",
    "    # get variables setting\n",
    "    if featureselector == 'passthrough':\n",
    "        variables = 'full_vars'\n",
    "    else:\n",
    "        variables = 'selected_vars'\n",
    "    \n",
    "    # get analysis type\n",
    "    if inclusion_var == 'total_bets':\n",
    "        analysis_type = 'main'\n",
    "    else:\n",
    "        analysis_type = 'sens'\n",
    "        \n",
    "    \n",
    "    # get model\n",
    "    if isinstance(estimator,LogisticRegression):\n",
    "        model = 'logit'\n",
    "\n",
    "    elif isinstance(estimator,RandomForestClassifier):\n",
    "        model = 'random_forest'\n",
    "         \n",
    "    \n",
    "    return pipe, analysis_type, variables, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get optimal classification threshold\n",
    "def get_optimal_cutoff_point(fpr, tpr, thresholds):\n",
    "    '''Get optimal classification cutoff.\n",
    "    \n",
    "    Get optimal classification cutoff by finding the threshold that maximizes \n",
    "    the difference between true positive rate (tpr) and false positive rate (fpr), \n",
    "    the two axes in a ROC curve. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    fpr, tpr, thresholds : output from sklearn.metrics.roc_curve method\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    opt_cutoff = thresholds[np.argmax(tpr - fpr)]\n",
    "    \n",
    "    return opt_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get classification based on cutoff and array of predicted probabilities\n",
    "def get_classification(array, cutoff=0.5):\n",
    "    '''Get classification from array of predicted probabilities.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array : array of int\n",
    "            Array of predicted probabilities\n",
    "    cutoff : int\n",
    "             Classification threshold value\n",
    "             \n",
    "    '''\n",
    "    \n",
    "    new_array=np.zeros(len(array))\n",
    "    new_array[array>cutoff]=1\n",
    "    \n",
    "    return new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate specificity\n",
    "def get_specificity(confusion_matrix):\n",
    "    '''Calculate specificity from confusion matrix.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    confusion_matrix : sklear.metrics.confusion_matrix.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    cm = np.array(confusion_matrix)\n",
    "    specificity = cm[0][0]/(cm[0]).sum()\n",
    "    \n",
    "    return specificity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Figure 1 and Supplementary Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_importances(clf, features):\n",
    "    '''Extract feature importances from fitted Random Forest Classification model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : fitted model\n",
    "    features : array of features\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    if len(features)!=clf.n_features_:\n",
    "        print('WARNING: len(features)!=len(n_features_) is True. Fitted model must correspond to indicated features.')\n",
    "        sys.exit()\n",
    "        \n",
    "    # clf.feature_importances:\n",
    "    # give a list of length X.shape[1], which indicates the variable importance for \n",
    "    # each feature in each in the order they appear in X. \n",
    "    importances=clf.feature_importances_\n",
    "    \n",
    "    # relative feature importances\n",
    "    #imp_sum = importances.sum()\n",
    "    #relative_importances = importances/imp_sum\n",
    "\n",
    "    # standard deviation for each feature's importance across all estimators\n",
    "    std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "                 axis=0)\n",
    "\n",
    "\n",
    "    # np.argsort():\n",
    "    # gives back a ordered (in ascending order) list, where first position indicates lowest value \n",
    "    # and last position indicates highest value. So, e.g. features[19] will give the name of the feautre with the \n",
    "    # lowest importance. \n",
    "    indices = np.argsort(importances)[::-1]\n",
    "\n",
    "    # create Dataframe w/ feature importance\n",
    "    feat_imp = pd.DataFrame({'features':features, \n",
    "                             'importances':importances, \n",
    "                             'std':std}).sort_values(by='importances',ascending=False)\n",
    "    \n",
    "    return feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_variable_names(header):\n",
    "    '''Create dictionary with variable names and their full names.'''\n",
    "    \n",
    "    features_fullnames = [\n",
    "        'Average Session Length',\n",
    "        'Bets per Day',\n",
    "        'Bets per Session',\n",
    "        'Days Gambled',\n",
    "        'Distinct Games per Session',\n",
    "        'Money Bet per Session',\n",
    "        'Net Loss per Session',\n",
    "        'Net Win per Session',\n",
    "        'Money Bet from Promotional Offers per Session',\n",
    "        'Sessions per Day',\n",
    "        'Total Bets',\n",
    "        'Total Money Bet',\n",
    "        'Total Net Loss',\n",
    "        'Total Net Win',\n",
    "        'Total Sessions',\n",
    "        'Total Money Bet from Promotional Offers', \n",
    "        'Variance in Bets per Session',\n",
    "        'Variance in Distinct Games per Session',\n",
    "        'Variance in Money Bet per Session',\n",
    "        'Variance in Average Session Length'\n",
    "    ]\n",
    "\n",
    "    header.sort()\n",
    "    dicc = dict(zip(header,features_fullnames))\n",
    "    \n",
    "    return dicc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
